{
  "project": "V-Ralph",
  "branchName": "ralph/v-ralph",
  "description": "V-Ralph - Python-based V-Lifecycle Agent replacing ralph.sh with watertight specs and semantic validation",
  "verificationCommands": {
    "typecheck": "python -m py_compile v_ralph.py",
    "test": "python -m pytest tests/ -v"
  },
  "userStories": [
    {
      "id": "US-001",
      "title": "Project scaffolding and CLI entry point",
      "description": "As a developer, I need the basic V-Ralph project structure so I can begin implementing the core modules.",
      "acceptanceCriteria": [
        "v_ralph.py exists and is executable (python v_ralph.py --help shows usage)",
        "Directory structure created: macro_v/, micro_v/, shared/, tests/",
        "Each module directory has __init__.py",
        "CLI shows 'run' and 'status' commands in help output",
        "python v_ralph.py --version outputs version string",
        "README.md documents installation and basic usage",
        "Typecheck passes: python -m py_compile v_ralph.py"
      ],
      "priority": 1,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-002",
      "title": "prd.yml read/write module",
      "description": "As the execution engine, I need to read story definitions and update their status so progress persists across iterations.",
      "acceptanceCriteria": [
        "shared/prd.py module exists",
        "load_prd(path) reads and parses prd.yml, returns typed dataclass",
        "save_prd(prd, path) writes prd.yml preserving structure",
        "get_pending_stories(prd) returns stories where passes is false",
        "mark_story_passed(prd, story_id) sets passes to true",
        "increment_attempts(prd, story_id) increments attempt counter",
        "Handles missing file gracefully with clear error message",
        "Unit tests in tests/test_prd.py cover all functions",
        "Typecheck passes: python -m py_compile shared/prd.py"
      ],
      "priority": 2,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-003",
      "title": "Claude CLI wrapper",
      "description": "As the execution engine, I need a clean interface to spawn stateless Claude instances for the retry loop.",
      "acceptanceCriteria": [
        "shared/claude.py module exists",
        "invoke_claude(prompt, timeout=300) spawns claude -p subprocess",
        "Returns tuple of (stdout, stderr, exit_code)",
        "Handles timeout gracefully, kills process, returns timeout error",
        "Process is fully terminated after call (no zombie processes)",
        "Unit tests in tests/test_claude.py mock subprocess for testing",
        "Typecheck passes: python -m py_compile shared/claude.py"
      ],
      "priority": 3,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-004",
      "title": "Progress tracking with two-tier structure",
      "description": "As the execution engine, I need to read learnings and append new ones so knowledge persists across iterations without bloating context.",
      "acceptanceCriteria": [
        "shared/progress.py module exists",
        "load_learnings(path) returns Patterns section + last 5 Recent History entries only",
        "append_progress(path, entry) adds new entry to Recent History section",
        "Older history entries remain in file but are not loaded for context",
        "Handles missing file gracefully (creates with template structure)",
        "Unit tests in tests/test_progress.py verify two-tier loading and appending",
        "Typecheck passes: python -m py_compile shared/progress.py"
      ],
      "priority": 4,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-005",
      "title": "Coder prompt template",
      "description": "As the coding agent, I need clear instructions so I implement stories correctly and update documentation.",
      "acceptanceCriteria": [
        "micro_v/prompts/coder.md exists",
        "Prompt includes placeholders: {{goal}}, {{files}}, {{criteria}}, {{learnings}}",
        "Prompt instructs agent to update README as part of implementation",
        "Prompt forbids touching files outside the whitelist",
        "Prompt forbids shortcuts like @ts-ignore, eslint-disable, any type",
        "Prompt includes section for learnings from progress.md",
        "README.md explains prompt customization options"
      ],
      "priority": 5,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-006",
      "title": "Micro-V executor loop without audit",
      "description": "As the execution engine, I need the core retry loop that writes code and runs validation.",
      "acceptanceCriteria": [
        "micro_v/executor.py module exists",
        "execute_story(story, config) implements the retry loop",
        "Loop steps: invoke coder via claude -p, run validation_command, check result",
        "On validation failure: retry with error output as context",
        "Circuit breaker: stop after max_retries (default 5)",
        "Returns structured result: success, failed, or escalated",
        "Logs each iteration with clear status output to terminal",
        "Unit tests in tests/test_executor.py cover success, failure, and circuit breaker paths",
        "Typecheck passes: python -m py_compile micro_v/executor.py"
      ],
      "priority": 6,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-007",
      "title": "Adversarial auditor prompt",
      "description": "As the semantic auditor, I need instructions that make me skeptical and thorough.",
      "acceptanceCriteria": [
        "micro_v/prompts/auditor.md exists",
        "Prompt frames auditor as skeptical QA engineer trying to find gaps",
        "Prompt lists specific checks: edge cases, intent vs letter of spec, unstated assumptions",
        "Prompt defines clear output format: PASS or RETRY: [feedback] or ESCALATE: [reason]",
        "Prompt emphasizes high bar for ESCALATE (design questions only, not bugs)",
        "Prompt includes examples showing PASS, RETRY, and ESCALATE scenarios",
        "README.md explains the three-layer validation model"
      ],
      "priority": 7,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-008",
      "title": "Semantic auditor module",
      "description": "As the validation layer, I need an adversarial reviewer to catch green build hallucinations.",
      "acceptanceCriteria": [
        "micro_v/auditor.py module exists",
        "audit_implementation(spec, diff) spawns fresh claude -p call",
        "Auditor receives only spec + diff (no context from coding session)",
        "Returns enum: PASS, RETRY with feedback string, or ESCALATE with reason",
        "Process is killed immediately after returning verdict",
        "ESCALATE only returned for genuine design ambiguity (high bar)",
        "Unit tests in tests/test_auditor.py verify each return type",
        "Typecheck passes: python -m py_compile micro_v/auditor.py"
      ],
      "priority": 8,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-009",
      "title": "Integrate semantic audit into executor",
      "description": "As the execution engine, I need the auditor as the third validation layer.",
      "acceptanceCriteria": [
        "executor.py calls auditor after validation_command passes",
        "On RETRY: loop back with auditor feedback as context",
        "On ESCALATE: exit loop, return escalated result with reason",
        "On PASS: proceed to commit step",
        "Audit retries count toward circuit breaker limit",
        "Integration tests cover: pass-through, retry loop, escalation",
        "Typecheck passes"
      ],
      "priority": 9,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-010",
      "title": "Git integration for commits",
      "description": "As the execution engine, I need to commit completed work so progress is captured in version control.",
      "acceptanceCriteria": [
        "shared/git.py module exists",
        "commit_story(story_id, title, files) stages only whitelisted files and commits",
        "Commit message format: feat: [ID] - [Title]",
        "Returns commit SHA on success",
        "Fails gracefully if unrelated dirty files exist (does not commit them)",
        "Unit tests in tests/test_git.py mock git commands",
        "Typecheck passes: python -m py_compile shared/git.py"
      ],
      "priority": 10,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-011",
      "title": "Status command",
      "description": "As a user, I want to see the current state of all stories.",
      "acceptanceCriteria": [
        "python v_ralph.py status reads prd.yml and displays table",
        "Table shows: ID, Title, Status (pass/fail/escalated), Attempts",
        "Shows total progress summary: X/Y stories complete",
        "Shows current branch name from prd.yml",
        "Handles missing prd.yml with helpful error message",
        "README.md documents the status command",
        "Typecheck passes"
      ],
      "priority": 11,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-012",
      "title": "Run command with full integration",
      "description": "As a user, I want to execute all pending stories autonomously.",
      "acceptanceCriteria": [
        "python v_ralph.py run executes all stories where passes is false",
        "--max-retries N flag overrides default retry limit of 5",
        "--story US-XXX flag runs single story only",
        "--dry-run flag shows what would run without executing",
        "On story success: commits changes, updates prd.yml, appends progress.md",
        "On escalation: stops loop, displays reason, exits with code 2",
        "On circuit breaker: marks story escalated, moves to next story",
        "Displays clear progress output during execution",
        "README.md documents all CLI flags",
        "Typecheck passes"
      ],
      "priority": 12,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-013",
      "title": "Macro-V planning skill for Claude Code",
      "description": "As a user planning inside Claude Code, I want interactive spec refinement that produces machine-verifiable specs.",
      "acceptanceCriteria": [
        "Skill file exists at .claude/skills/v-ralph-planning/SKILL.md",
        "Skill guides Claude to ask clarifying questions until all criteria are verifiable",
        "Each acceptance criterion must have a verify command (grep, test, file exists)",
        "Skill enforces README update criterion for every story",
        "Skill enforces files whitelist for every story",
        "Outputs valid prd.yml to project directory",
        "Skill includes examples of good vs bad acceptance criteria",
        "README.md explains how to invoke the planning skill"
      ],
      "priority": 13,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-014",
      "title": "End-to-end integration test",
      "description": "As a developer, I need a test proving the full V-model flow works.",
      "acceptanceCriteria": [
        "Test fixture exists: tests/fixtures/ with minimal project and simple prd.yml",
        "Test runs v_ralph.py run against fixture with mocked Claude calls",
        "Verifies: story executed, validation passed, audit passed",
        "Verifies: prd.yml updated with passes true",
        "Verifies: progress.md has new entry",
        "Test can run in CI with deterministic mocked responses",
        "README.md documents how to run integration tests",
        "Test passes: python -m pytest tests/test_integration.py -v"
      ],
      "priority": 14,
      "passes": false,
      "notes": ""
    }
  ]
}
